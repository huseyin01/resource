{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Segmentation in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter-1 Cohort Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign daily acquisition cohort\n",
    "\n",
    "1. once: “YYYY-MM-DD HH:MM:SS” formatinda olan bir “datetime object”in sadece “date” bilgisini cekmis oluyorum. “time” bilgisine ihtiyacim olmadigi durumlarda kullanmak icin.\n",
    "2. daha sonra \"groupby\" metodu ile her bir \"customer\"in alisveris yaptigi tum tarihleri bir degiskene atiyorum (\"grouping)\n",
    "3. bu degiskenin en kucuk degerini \".transorm('min') fonksiyonu ile bularak, musterinin alisveris yaptigi ilk gune ulasmis oluyorum.\n",
    "4. boylece analizimin ilk adimi olan \"cohort\" (grup [burada musteri grubu]) olusturulmus oluyor. yani tum musteriler alisveris yaptigi ilk gune gore gruplandirilmis oluyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that will parse the date\n",
    "def get_day(x): return dt.datetime(x.year, x.month, x.day) \n",
    "\n",
    "# Create InvoiceDay column\n",
    "online['InvoiceDay'] = online['InvoiceDate'].apply(get_day) \n",
    "\n",
    "# Group by CustomerID and select the InvoiceDay value\n",
    "grouping = online.groupby('CustomerID')['InvoiceDay'] \n",
    "\n",
    "# Assign a minimum InvoiceDay value to the dataset\n",
    "online['CohortDay'] = grouping.transform('min')\n",
    "\n",
    "# View the top 5 rows\n",
    "print(online.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate time offset in days\n",
    "\n",
    "1. sirada \"time offset\", yani zaman farkinin hesaplanmasi var. gun uzerinden hesaplama yapiliyor burada.\n",
    "2. hesaplama \"integer\" degerler uzerinden oldugu icin, oncelikle \"date\" bilgisi bir fonksiyon ile integer degerlere donusturuluyor.\n",
    "3. yani once \"A\" (invoice date) ve \"B\" (cohort date) i rakamsal olarak olusturuyoruz, sonra \"A-B\" islemini yapiyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_int(df, column):\n",
    "    year = df[column].dt.year\n",
    "    month = df[column].dt.month\n",
    "    day = df[column].dt.day\n",
    "    return year, month, day\n",
    "\n",
    "# Get the integers for date parts from the InvoiceDaycolumn\n",
    "invoice_year, invoice_month, invoice_day = get_date_int(online, 'InvoiceDay')\n",
    "\n",
    "# Get the integers for date parts from the CohortDay column\n",
    "cohort_year, cohort_month, cohort_day = get_date_int(online, 'CohortDay')\n",
    "\n",
    "# Calculate difference in years\n",
    "years_diff = invoice_year - cohort_year\n",
    "\n",
    "# Calculate difference in months\n",
    "months_diff = invoice_month - cohort_month\n",
    "\n",
    "# Calculate difference in days\n",
    "days_diff = invoice_day - cohort_day\n",
    "\n",
    "# Extract the difference in days from all previous values\n",
    "online['CohortIndex'] = years_diff * 365 + months_diff * 30 + days_diff + 1\n",
    "print(online.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count monthly active customers from each cohort "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping = online.groupby(['CohortMonth', 'CohortIndex'])\n",
    "cohort_data = grouping['CustomerID'].apply(pd.Series.nunique)\n",
    "cohort_data = cohort_data.reset_index()\n",
    "cohort_counts = cohort_data.pivot(index='CohortMonth',\n",
    "                                  columns='CohortIndex',\n",
    "                                  values='CustomerID')\n",
    "print(cohort_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate retention rate from scratch\n",
    "\n",
    "1. herbir cohortmonth'dan, analiz baslangic tarihinden bitis tarihine kadar, esas aldigimiz zaman dilimi adedince gruplara bolduk.\n",
    "2. bu gruplardaki \"unique\" musteri sayisini bir degiskene atadik (reset_index) demeyi untmadik.\n",
    "3. sonra, index'i \"cohortdate\" sutunu \"cohort time period\", degeri de \"farkli musteri sayisi\" olan bir \"pivot table\" olusturduk.\n",
    "4. bu tabledaki tum degerleri, her bir grubun baslangictaki sayisina bolerek, o gruptan zaman icinde ne kadarini muhafa edebildigimizi gorduk. buna \"retention rate\", yani \"elde tutma/muhafa etme orani\" deniliyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping = online.groupby(['CohortMonth', 'CohortIndex'])\n",
    "\n",
    "# Count the number of unique values per customer ID\n",
    "cohort_data = grouping['CustomerID'].apply(pd.Series.nunique).reset_index()\n",
    "\n",
    "# Create a pivot \n",
    "cohort_counts = cohort_data.pivot(index='CohortMonth', \n",
    "                                  columns='CohortIndex', \n",
    "                                  values='CustomerID')\n",
    "\n",
    "# Select the first column and store it to cohort_sizes\n",
    "cohort_sizes = cohort_counts.iloc[:,0]\n",
    "\n",
    "# Divide the cohort count by cohort sizes along the rows\n",
    "retention = cohort_counts.divide(cohort_sizes, axis=0)\n",
    "\n",
    "retention.round(3) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate average price\n",
    "\n",
    "1. birincisi, almam gereken en onemli noktalardan biri \"grouping\" mantigi. burada grouping, \"online\" setinin tamamini iceriyor gibi ama \"cohort_data\" sadece 3 \"feature\" iceriyor. \n",
    "2. mantigi su olabilir: biz \"cohort_data\"ya sadece \"unit price\"i atadik ama \"grouping\" degiskeni uzerinden yani, \"cohortminth\" ve \"cohortindex\" bilgilerine gore siralanmis olan veri setini kullandik. dolayisi ile tek bir degiskenini kullansam bile, onunla birlikte gruplandirma icin kullandigi \"feature\"lari da getiriyor. umarim dogru anlamisimdir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a groupby object and pass the monthly cohort and cohort index as a list\n",
    "grouping = online.groupby(['CohortMonth', 'CohortIndex']) \n",
    "\n",
    "# Calculate the average of the unit price column\n",
    "cohort_data = grouping['UnitPrice'].mean()\n",
    "\n",
    "# Reset the index of cohort_data\n",
    "cohort_data = cohort_data.reset_index()\n",
    "\n",
    "# Create a pivot \n",
    "average_quantity = cohort_data.pivot(index='CohortMonth', \n",
    "                                     columns='CohortIndex', \n",
    "                                     values='UnitPrice')\n",
    "print(average_quantity.round(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort analysis visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Retention rates')\n",
    "sns.heatmap(data = retention,\n",
    "            annot = True,\n",
    "            fmt = '.0%',\n",
    "            vmin = 0.0,\n",
    "            vmax = 0.5,\n",
    "            cmap = 'BuGn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter-2 Recency, Frequency, Monetary Value analysis"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Recency - days since last customer transaction\n",
    "Frequency - number of transactions in the last 12 months\n",
    "Monetary Value - total spend in the last 12 months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Spend quintiles (q=5)\n",
    "\n",
    "musterilerin, yaptiklari harcamaya gore 4 esit gruba bolunmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spend quartile with 4 groups and labels ranging from 1 through 4 \n",
    "spend_quartile = pd.qcut(data['Spend'], q=4, labels=range(1,5))\n",
    "\n",
    "# Assign the quartile values to the Spend_Quartile column in data\n",
    "data['Spend_Quartile'] = spend_quartile\n",
    "\n",
    "# Print data with sorted Spend values\n",
    "print(data.sort_values('Spend'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Recency deciles (q=10)\n",
    "\n",
    "ayni seyi \"recency\" icin yapiyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store labels from 4 to 1 in a decreasing order\n",
    "r_labels = list(range(4, 0, -1))\n",
    "\n",
    "# Create a spend quartile with 4 groups and pass the previously created labels \n",
    "recency_quartiles = pd.qcut(data['Recency_Days'], q=4, labels=r_labels)\n",
    "\n",
    "# Assign the quartile values to the Recency_Quartile column in `data`\n",
    "data['Recency_Quartile'] = recency_quartiles \n",
    "\n",
    "# Print `data` with sorted Recency_Days values\n",
    "print(data.sort_values('Recency_Days'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate RFM values\n",
    "\n",
    "1. snapshot'i olusturmamizin nedeni, analiz gununu bugunmus gibi gostermek.\n",
    "2. datamart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_date = max(online.InvoiceDate) + datetime.timedelta(days=1)\n",
    "\n",
    "# Calculate Recency, Frequency and Monetary value for each customer \n",
    "datamart = online.groupby(['CustomerID']).agg({\n",
    "    'InvoiceDate': lambda x: (snapshot_date - x.max()).days,\n",
    "    'InvoiceNo': 'count',\n",
    "    'TotalSum': 'sum'})\n",
    "\n",
    "# Rename the columns \n",
    "datamart.rename(columns={'InvoiceDate': 'Recency',\n",
    "                         'InvoiceNo': 'Frequency',\n",
    "                         'TotalSum': 'MonetaryValue'}, inplace=True)\n",
    "\n",
    "# Print top 5 rows\n",
    "print(datamart.head())\n",
    "\n",
    "            Frequency  MonetaryValue  Recency\n",
    "CustomerID                                   \n",
    "12747              25         948.70        3\n",
    "12748             888        7046.16        1\n",
    "12749              37         813.45        4\n",
    "12820              17         268.02        4\n",
    "12822               9         146.15       71"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate 3 groups for Recency, Frequency and MonetaryValue  & Calculate RFM Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels for Recency, Frequency and MonetaryValue\n",
    "r_labels = range(3, 0, -1); f_labels = range(1, 4); m_labels = range(1, 4)\n",
    "\n",
    "# Assign these labels to three equal percentile groups \n",
    "r_groups = pd.qcut(datamart['Recency'], q=3, labels=r_labels)\n",
    "f_groups = pd.qcut(datamart['Frequency'], q=3, labels=f_labels)\n",
    "m_groups = pd.qcut(datamart['MonetaryValue'], q=3, labels=m_labels)\n",
    "\n",
    "# Create new columns R and F \n",
    "datamart = datamart.assign(R=r_groups.values, F=f_groups.values, M=m_groups.values)\n",
    "\n",
    "# Calculate RFM_Score\n",
    "datamart['RFM_Score'] = datamart[['R','F','M']].sum(axis=1)\n",
    "print(datamart['RFM_Score'].head())\n",
    "\n",
    "def join_rfm(x): \n",
    "    return str(x['R']) + str(x['F']) + str(x['M'])\n",
    "\n",
    "datamart['RFM_Segment'] = datamart.apply(join_rfm, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating custom segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define rfm_level function\n",
    "def rfm_level(df):\n",
    "    if df['RFM_Score'] >= 10:\n",
    "        return 'Top'\n",
    "    elif (df['RFM_Score'] >= 6) and (df['RFM_Score'] < 10):\n",
    "        return 'Middle'\n",
    "    else:\n",
    "        return 'Low'\n",
    "\n",
    "# Create a new variable RFM_Level\n",
    "datamart['RFM_Level'] = datamart.apply(rfm_level, axis=1)\n",
    "\n",
    "# Print the header with top 5 rows to the console\n",
    "print(datamart.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing custom segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average values for each RFM_Level, and return a size of each segment \n",
    "rfm_level_agg = datamart.groupby('RFM_Level').agg({\n",
    "    'Recency': 'mean',\n",
    "    'Frequency': 'mean',\n",
    "    \n",
    "  \t# Return the size of each segment\n",
    "    'MonetaryValue': ['mean', 'count']\n",
    "}).round(1)\n",
    "\n",
    "# Print the aggregated dataset\n",
    "print(rfm_level_agg)\n",
    "\n",
    "         Frequency MonetaryValue       Recency\n",
    "               mean          mean count    mean\n",
    "RFM_Level                                      \n",
    "Low             3.2          52.7  1075   180.8\n",
    "Middle         10.7         202.9  1547    73.9\n",
    "Top            47.1         959.7  1021    20.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter-3 Data pre-processing for clustering"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Key k-means assumptions\n",
    "Symmetric distribution of variables (not skewed)\n",
    "Variables with same average values\n",
    "Variables with same variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect skewed variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "sns.distplot(datamart['Recency'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manage skewness Logarithmic transformation (positive values only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "frequency_log= np.log(datamart['Frequency'])\n",
    "sns.distplot(frequency_log)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centering and scaling variables"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Identifying an issue: \n",
    "    Analyze key statistics of the dataset\n",
    "    Compare mean and standard deviation\n",
    "\n",
    "1. Centering variables with different means\n",
    "    Centering variables is done by subtracting average value from each observation\n",
    "2. Scaling variables with different variance\n",
    "    Scaling variables is done by dividing them by standard deviation of each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_centered = data - data.mean()\n",
    "data_centered.describe().round(2)\n",
    "\n",
    "data_scaled = data / data.std()\n",
    "data_scaled.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(datamart_rfm)\n",
    "datamart_normalized = scaler.transform(datamart_rfm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process RFM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unskew the data\n",
    "datamart_log = np.log(datamart_rfm)\n",
    "\n",
    "# Initialize a standard scaler and fit it\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(datamart_log)\n",
    "\n",
    "# Scale and center the data\n",
    "datamart_normalized = scaler.transform(datamart_log)\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "datamart_normalized = pd.DataFrame(data=datamart_normalized, index=datamart_rfm.index, columns=datamart_rfm.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter-4 Customer Segmentation with K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import KMeans \n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Initialize KMeans\n",
    "kmeans = KMeans(n_clusters=3, random_state=1) \n",
    "\n",
    "# Fit k-means clustering on the normalized data set\n",
    "kmeans.fit(datamart_normalized)\n",
    "\n",
    "# Extract cluster labels\n",
    "cluster_labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign labels to raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame by adding a new cluster label column\n",
    "datamart_rfm_k3 = datamart_rfm.assign(Cluster=cluster_labels)\n",
    "\n",
    "# Group the data by cluster\n",
    "grouped = datamart_rfm_k3.groupby(['Cluster'])\n",
    "\n",
    "# Calculate average RFM values and segment sizes per cluster value\n",
    "grouped.agg({\n",
    "    'Recency': 'mean',\n",
    "    'Frequency': 'mean',\n",
    "    'MonetaryValue': ['mean', 'count']\n",
    "  }).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the number of Clusters\n",
    "\n",
    "Methods to define the number of clusters\n",
    "    \n",
    "    a. Visual methods - elbow criterion\n",
    "    b. Mathematical methods - silhouette coefficient\n",
    "    c. Experimentation and interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elbow criterion method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import key libraries\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Fit KMeans and calculate SSE for each *k*\n",
    "sse = {}\n",
    "for k in range(1, 11):\n",
    "kmeans = KMeans(n_clusters=k, random_state=1)\n",
    "kmeans.fit(data_normalized)\n",
    "sse[k] = kmeans.inertia_ # sum of squared distances to closest cluster cente\n",
    "\n",
    "# Plot SSE for each *k*\n",
    "plt.title('The Elbow Method')\n",
    "plt.xlabel('k'); plt.ylabel('SSE')\n",
    "sns.pointplot(x=list(sse.keys()), y=list(sse.values()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile and interpret segments\n",
    "\n",
    "Approaches to build customer personas\n",
    "    \n",
    "    a. Summary statistics for each cluster e.g. average RFM values\n",
    "    b. Snake plots (from market research\n",
    "    c. Relative importance of cluster attributes compared to population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamart_rfm_k2 = datamart_rfm.assign(Cluster = cluster_labels)\n",
    "\n",
    "datamart_rfm_k2.groupby(['Cluster']).agg({\n",
    "'Recency': 'mean',\n",
    "'Frequency': 'mean',\n",
    "'MonetaryValue': ['mean', 'count'],\n",
    "}).round(0)\n",
    "\n",
    "Repeat the same for k=3 Compare average RFM values of each clustering solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snake plots to understand and compare segments\n",
    "\n",
    "    a. Market research technique to compare different segments\n",
    "    b. Visual representation of each segment's attributes\n",
    "    c. Need to first normalize data (center & scale)\n",
    "    d. Plot each cluster's average normalized values of each attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare data for a snake plot\n",
    "\n",
    "# Transform datamart_normalized as DataFrame and add a Cluster column\n",
    "\n",
    "datamart_normalized = pd.DataFrame(datamart_normalized,\n",
    "index=datamart_rfm.index,\n",
    "columns=datamart_rfm.columns)\n",
    "datamart_normalized['Cluster'] = datamart_rfm_k3['Cluster']\n",
    "\n",
    "# Melt the data into a long format so RFM values and metric names are stored in 1 column each\n",
    "datamart_melt = pd.melt(datamart_normalized.reset_index(),\n",
    "id_vars=['CustomerID', 'Cluster'],\n",
    "value_vars=['Recency', 'Frequency', 'MonetaryValue'],\n",
    "var_name='Attribute',\n",
    "value_name='Value')\n",
    "\n",
    "# Visualize a snake plot\n",
    "plt.title('Snake plot of standardized variables')\n",
    "sns.lineplot(x=\"Attribute\", y=\"Value\", hue='Cluster', data=datamart_melt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative importance of segment attributes\n",
    "\n",
    "    a. Useful technique to identify relative importance of each segment's attribute\n",
    "    b. Calculate average values of each cluster\n",
    "    c. Calculate average values of population\n",
    "    d. Calculate importance score by dividing them and subtracting 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_avg = datamart_rfm_k3.groupby(['Cluster']).mean()\n",
    "population_avg = datamart_rfm.mean()\n",
    "relative_imp = cluster_avg / population_avg - 1\n",
    "\n",
    "# Analyze and plot relative importance\n",
    "\n",
    "# The further a ratio is from 0, the more important that attribute is for a segment\n",
    "relative to the total population.\n",
    "\n",
    "relative_imp.round(2)\n",
    "\n",
    "Recency Frequency MonetaryValue\n",
    "Cluster\n",
    "0 -0.82 1.68 1.83\n",
    "1 0.84 -0.84 -0.86\n",
    "2 -0.15 -0.34 -0.42\n",
    "\n",
    "# Plot a heatmap for easier interpretation:\n",
    "plt.figure(figsize=(8, 2))\n",
    "plt.title('Relative importance of attributes')\n",
    "sns.heatmap(data=relative_imp, annot=True, fmt='.2f', cmap='RdYlGn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Updated RFM data\n",
    "Same RFM values plus additional Tenure variable\n",
    "Tenure - time since the first transaction\n",
    "Defines how long the customer has been with the company"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
