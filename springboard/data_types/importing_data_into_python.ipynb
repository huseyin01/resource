{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring your working directory\n",
    "\n",
    "In order to import data into Python, you should first have an idea of what files are in your working directory.\n",
    "\n",
    "IPython, which is running on DataCamp's servers, has a bunch of cool commands, including its magic commands. For example, starting a line with ! gives you complete system shell access. This means that the IPython magic command ! ls will display the contents of your current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.1_data_types.ipynb             cta_daily_summary_tools.txt\r\n",
      "baby_names.txt                   deneme\r\n",
      "chicago_crime.txt                importing_data_into_python.ipynb\r\n",
      "cta_daily_station_tools.txt\r\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing entire text files\n",
    "\n",
    "Here you'll get experience opening a text file, printing its contents to the shell and, finally, closing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'chicago_crime.txt'\n",
    "file = open(filename, mode='r')\n",
    "text = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/onlyone/Documents/Springboard/Datas'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/onlyone/Documents/Springboard\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170710_NATURAL LANGUAGE PROCESSING PROJECTS.docx\r\n",
      "20170710_NATURAL LANGUAGE PROCESSING PROJECTS.pdf\r\n",
      "20180710_1. Introduction- What Is Data Science? - Doing Data Science [Book].pdf\r\n",
      "20180710_Thirteen Companies That Use Deep Learning To Produce Actionable Results.docx\r\n",
      "20180710_Thirteen Companies That Use Deep Learning To Produce Actionable Results.pdf\r\n",
      "20180711_How Successful People Think Differently – The Mission – Medium.pdf\r\n",
      "20180711_What Makes A LinkedIn Profile Great.pdf\r\n",
      "20180712_5 LinkedIn Summary Templates to Try - The Muse.pdf\r\n",
      "\u001b[34mCapstone Projects\u001b[m\u001b[m/\r\n",
      "\u001b[34mDatas\u001b[m\u001b[m/\r\n",
      "Importing Data into Python_Slides.pdf\r\n",
      "\u001b[34mInterview\u001b[m\u001b[m/\r\n",
      "MINST.txt\r\n",
      "\u001b[34mPrework Notes\u001b[m\u001b[m/\r\n",
      "Thirteen Companies That Use Deep Learning To Produce Actionable Results.pdf\r\n",
      "Unit Plan-1 : What is Data Science - Google Docs.pdf\r\n",
      "What Makes A LinkedIn Profile Great.docx\r\n",
      "\u001b[34mdata_types\u001b[m\u001b[m/\r\n",
      "importing_data_into_python-1.1.pdf\r\n",
      "importing_data_into_python-1.2.pdf\r\n",
      "importing_data_into_python-1.pdf\r\n",
      "seaslugs.txt\r\n",
      "titanic.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('seaslugs.txt', mode='r') as ahmet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(ahmet.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time\tPercent\n",
      "99\t0.0\n"
     ]
    }
   ],
   "source": [
    "print(text[:19]) \n",
    "# burada n'nci elemanin ciktini al dersek sadece bir karakter cikartir, cunku tum veriyi duz yazi olarak algiliyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(file.closed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date,Block,Primary Type,Description,Location Description,Arrest,Domestic,District\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('chicago_crime.txt') as file:\n",
    "    print(file.readline())\n",
    "\n",
    "    #print(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using NumPy to import flat files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'MINST.txt'\n",
    "data = np.loadtxt(filename, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [2. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [5. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 29-31 not seen yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = data[21, 1:]\n",
    "im_sq = np.reshape(im, (28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x106db6b00>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(im_sq, cmap='Greys', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customizing your NumPy import\n",
    "\n",
    "What if there are rows, such as a header, that you don't want to import? What if your file has a delimiter other than a comma? What if you only wish to import particular columns?\n",
    "\n",
    "There are a number of arguments that np.loadtxt() takes that you'll find useful: delimiter changes the delimiter that loadtxt() is expecting, for example, you can use ',' and '\\t' for comma-delimited and tab-delimited respectively; skiprows allows you to specify how many rows (not indices) you wish to skip; usecols takes a list of the indices of the columns you wish to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(filename, delimiter=',', skiprows=1, usecols=[0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['99' '0.067']\n"
     ]
    }
   ],
   "source": [
    "print(data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('seaslugs.txt', delimiter='\\t', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Time' 'Percent']\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_float = np.loadtxt('seaslugs.txt', delimiter='\\t', dtype=float, skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.    0.533]\n"
     ]
    }
   ],
   "source": [
    "print(data_float[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data_float[:, 0], data_float[:, 1])\n",
    "plt.xlabel('time (min.)')\n",
    "plt.ylabel('percentage of larvae')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with mixed datatypes (1)\n",
    "\n",
    "Much of the time you will need to import datasets which have different datatypes in different columns; one column may contain strings and another floats, for example. The function np.loadtxt() will freak at this. There is another function, np.genfromtxt(), which can handle such structures. If we pass dtype=None to it, it will figure out what types each column should be.\n",
    "\n",
    "Import 'titanic.csv' using the function np.genfromtxt() as follows:\n",
    "\n",
    "data = np.genfromtxt('titanic.csv', delimiter=',', names=True, dtype=None)\n",
    "Here, the first argument is the filename, the second specifies the delimiter , and the third argument names tells us there is a header. Because the data are of different types, data is an object called a structured array. Because numpy arrays have to contain elements that are all the same type, the structured array solves this by being a 1D array, where each element of the array is a row of the flat file imported. You can test this by checking out the array's shape in the shell by executing np.shape(data).\n",
    "\n",
    "Acccessing rows and columns of structured arrays is super-intuitive: to get the ith row, merely execute data[i] and to get the column with name 'Fare', execute data['Fare']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/onlyone/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt('titanic.csv', delimiter=',', names=True, dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 11)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 3, b'male', 2., 3, 1, b'349909', 21.075, b'', b'S')\n"
     ]
    }
   ],
   "source": [
    "print(data[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with mixed datatypes (2)\n",
    "\n",
    "You have just used np.genfromtxt() to import data containing mixed datatypes. There is also another function np.recfromcsv() that behaves similarly to np.genfromtxt(), except that its default dtype is None. In this exercise, you'll practice using this to achieve the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/onlyone/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py:2266: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  output = genfromtxt(fname, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "d = np.recfromcsv('titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0, 3, b'male', 22., 1, 0, b'A/5 21171',  7.25  , b'', b'S')\n",
      " (2, 1, 1, b'female', 38., 1, 0, b'PC 17599', 71.2833, b'C85', b'C')\n",
      " (3, 1, 3, b'female', 26., 0, 0, b'STON/O2. 3101282',  7.925 , b'', b'S')]\n"
     ]
    }
   ],
   "source": [
    "print(d[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using pandas to import flat files as DataFrames (1)\n",
    "\n",
    "In the last exercise, you were able to import flat files containing columns with different datatypes as numpy arrays. However, the DataFrame object in pandas is a more appropriate structure in which to store such data and, thankfully, we can easily import files of mixed data types as DataFrames using the pandas functions read_csv() and read_table()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch  \\\n",
       "0            1         0       3    male  22.0      1      0   \n",
       "1            2         1       1  female  38.0      1      0   \n",
       "2            3         1       3  female  26.0      0      0   \n",
       "3            4         1       1  female  35.0      1      0   \n",
       "4            5         0       3    male  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin Embarked  \n",
       "0         A/5 21171   7.2500   NaN        S  \n",
       "1          PC 17599  71.2833   C85        C  \n",
       "2  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3            113803  53.1000  C123        S  \n",
       "4            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with missing values and incorrect data types /// baska bir DataCamp makalesinden alinti. eksik degerli sutunda diger degerlerde otomatik olarak \"object\" olarak algilaniyorki, bu durumda float ya da int degerler ile islem yapmak mumkun olmuyor. bu problemi asmak icin eksik olan degerlere \"na_values\" ile atama yapiyoruz\n",
    "# df = pd.read_csv(\"data/cereal.csv\", skiprows = 1, na_values = ['no info', '.'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using pandas to import flat files as DataFrames (2)\n",
    "\n",
    "In the last exercise, you were able to import flat files into a pandas DataFrame. As a bonus, it is then straightforward to retrieve the corresponding numpy array using the attribute values. You'll now have a chance to do this using the MNIST dataset, which is available as digits.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'titanic.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(file, nrows=5, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(data_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customizing your pandas import\n",
    "\n",
    "The pandas package is also great at dealing with many of the issues you will encounter when importing data as a data scientist, such as comments occurring in flat files, empty lines and missing values. Note that missing values are also commonly referred to as NA or NaN. To wrap up this chapter, you're now going to import a slightly corrupted copy of the Titanic dataset titanic_corrupt.txt, which\n",
    "\n",
    "* Dealing with missing values and incorrect data types /// baska bir DataCamp makalesinden alinti. eksik degerli sutunda diger degerlerde otomatik olarak \"object\" olarak algilaniyorki, bu durumda float ya da int degerler ile islem yapmak mumkun olmuyor. bu problemi asmak icin eksik olan degerlere \"na_values\" ile atama yapiyoruz. sep (the pandas version of delim)\n",
    "\n",
    "* df = pd.read_csv(\"data/cereal.csv\", skiprows = 1, na_values = ['no info', '.', 'Nothing])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'titanic_corrupt.txt'\n",
    "data = pd.read_csv(file, sep='\\t', comment='#', na_values='Nothing')\n",
    "print(data.head())\n",
    "pd.DataFrame.hist(data[['Age']])\n",
    "plt.xlabel('Age (years)')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to other file types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not so flat any more\n",
    "\n",
    "In Chapter 1, you learned how to use the IPython magic command ! ls to explore your current working directory. You can also do this natively in Python using the library os, which consists of miscellaneous operating system interfaces.\n",
    "\n",
    "The first line of the following code imports the library os, the second line stores the name of the current directory in a string called wd and the third outputs the contents of the directory in a list to the shell.\n",
    "\n",
    "import os\n",
    "wd = os.getcwd()\n",
    "os.listdir(wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/onlyone/Documents'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dene.txt',\n",
       " 'a2.1.py',\n",
       " 'HALIL Dta Scıence Notları.docx',\n",
       " '~$Book1.xlsx',\n",
       " '.DS_Store',\n",
       " 'Tax E-filing_1.pdf',\n",
       " 'test1_for_a2.py',\n",
       " '.localized',\n",
       " 'Book1.xlsx',\n",
       " 'Lease Contract_Final.pdf',\n",
       " 'CV_Huseyin YILMAZ.pages',\n",
       " 'test.py',\n",
       " 'data1.jpg',\n",
       " 'data1.1.jpg',\n",
       " 'Springboard',\n",
       " 'home challenga',\n",
       " 'Lease Contract_1221SG_2018-2019.pdf',\n",
       " 'Notice of help.pages',\n",
       " 'a2.py',\n",
       " 'test2_for_a2.py']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading a pickled file\n",
    "\n",
    "There are a number of datatypes that cannot be saved easily to flat files, such as lists and dictionaries. If you want your files to be human readable, you may want to save them as text files in a clever manner. JSONs, which you will see in a later chapter, are appropriate for Python dictionaries.\n",
    "\n",
    "However, if you merely want to be able to import them into Python, you can serialize them. All this means is converting the object into a sequence of bytes, or a bytestream.\n",
    "\n",
    "In this exercise, you'll import the pickle package, open a previously pickled data structure from a file and load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('data.pkl', 'rb') as file:\n",
    "    d = pickle.load(file)\n",
    "\n",
    "print(d)\n",
    "print(type(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'June': '69.4', 'Aug': '85', 'Airline': '8', 'Mar': '84.4'}\n",
    "<class 'dict'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listing sheets in Excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "file='battledeath.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "hakan=pd.ExcelFile(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2002', '2004']\n"
     ]
    }
   ],
   "source": [
    "print(hakan.sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pandas.io.excel.ExcelFile object at 0x115b59cf8>\n"
     ]
    }
   ],
   "source": [
    "print(hakan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing sheets from Excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  War, age-adjusted mortality due to       2002\n",
      "0                        Afghanistan  36.083990\n",
      "1                            Albania   0.128908\n",
      "2                            Algeria  18.314120\n",
      "3                            Andorra   0.000000\n",
      "4                             Angola  18.964560\n"
     ]
    }
   ],
   "source": [
    "hakan1=hakan.parse('2002') # sheet name as string # parse = ayristirmak\n",
    "print(hakan1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  War, age-adjusted mortality due to       2002\n",
      "0                        Afghanistan  36.083990\n",
      "1                            Albania   0.128908\n",
      "2                            Algeria  18.314120\n",
      "3                            Andorra   0.000000\n",
      "4                             Angola  18.964560\n"
     ]
    }
   ],
   "source": [
    "hakan2=hakan.parse(0) # sheet name as a float\n",
    "print(hakan2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customizing your spreadsheet import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Country  AMM due to War (2002)\n",
      "0              Albania               0.128908\n",
      "1              Algeria              18.314120\n",
      "2              Andorra               0.000000\n",
      "3               Angola              18.964560\n",
      "4  Antigua and Barbuda               0.000000\n"
     ]
    }
   ],
   "source": [
    "hakan1 = hakan.parse(0, skiprows=1, names=['Country', 'AMM due to War (2002)'])\n",
    "print(hakan1.head())\n",
    "\n",
    "# ?????? burada, names'in altina yazilan \"'AMM due to War (2002)'\" ifade kaldirildiginda kod calismiyor. nedenini anlamadim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hakan2 = hakan.parse(1, parse_cols=[0], skiprows=1, names=['Country'])\n",
    "print(hakan2.head())\n",
    "\n",
    "# bu komut calismadi, neredeyse exercise'daki ile ayni ifadeler, anlamadim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing SAS/Stata files using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to import SAS7BDAT\n",
    "# from sas7bdat import SAS7BDAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sas7bdat import SAS7BDAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with SAS7BDAT('sales.sas7bdat') as file\n",
    "    df_sas = file.to_data_frame()\n",
    "print(df_sas.head())\n",
    "\n",
    "# Plot histogram of DataFrame features (pandas and pyplot already imported)\n",
    "pd.DataFrame.hist(df_sas[['P']])\n",
    "plt.ylabel('count')\n",
    "plt.show()\n",
    "\n",
    "# SAS7BDAT ile ilgii komutu kabul etmedigi icin calistiramadim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import Stata files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_stata('disarea.dta')\n",
    "print(df.head())\n",
    "\n",
    "# Plot histogram of one column of the DataFrame\n",
    "pd.DataFrame.hist(df[['disa10']])\n",
    "plt.xlabel('Extent of disease')\n",
    "plt.ylabel('Number of coutries')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using h5py to import HDF5 files\n",
    "\n",
    "In this exercise, you'll import it using the h5py library. You'll also print out its datatype to confirm you have imported it correctly. You'll then study the structure of the file in order to see precisely what HDF groups it contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "# Assign filename: file\n",
    "file = 'LIGO_data.hdf5'\n",
    "\n",
    "# Load file: data\n",
    "data = h5py.File(file, 'r')\n",
    "\n",
    "# Print the datatype of the loaded file\n",
    "print(type(data))\n",
    "\n",
    "# Print the keys of the file\n",
    "for key in data.keys():\n",
    "    print(key)\n",
    "    \n",
    "<class 'h5py._hl.files.File'>\n",
    "Description\n",
    "DescriptionURL\n",
    "Detector\n",
    "Duration\n",
    "GPSstart\n",
    "Observatory\n",
    "Type\n",
    "UTCstart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting data from your HDF5 file\n",
    "\n",
    "In this exercise, you'll extract some of the LIGO experiment's actual data from the HDF5 file and you'll visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the HDF5 group: group\n",
    "group = data['strain']\n",
    "\n",
    "# Check out keys of group\n",
    "for key in group.keys():\n",
    "    print(key)\n",
    "\n",
    "# Set variable equal to time series data: strain\n",
    "strain = data['strain']['Strain'].value\n",
    "\n",
    "# Set number of time points to sample: num_samples\n",
    "num_samples = 10000\n",
    "\n",
    "# Set time vector\n",
    "time = np.arange(0, 1, 1/num_samples)\n",
    "\n",
    "# Plot data\n",
    "plt.plot(time, strain[:num_samples])\n",
    "plt.xlabel('GPS Time (s)')\n",
    "plt.ylabel('strain')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading .mat files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "mat = scipy.io.loadmat('albeck_gene_expression.mat')\n",
    "\n",
    "# scipy.io.savemat -> write mat files\n",
    "\n",
    "print(type(mat))\n",
    "<class 'dict'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The structure of .mat in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Print the keys of the MATLAB dictionary\n",
    "for key in mat.keys():\n",
    "    print(key)\n",
    "\n",
    "# ya da dogrudan \"print(mat.keys())\"\n",
    "\n",
    "# Print the type of the value corresponding to the key 'CYratioCyt'\n",
    "print(type(mat['CYratioCyt']))\n",
    "\n",
    "# Print the shape of the value corresponding to the key 'CYratioCyt'\n",
    "print(np.shape(mat['CYratioCyt']))\n",
    "\n",
    "# Subset the array and plot it\n",
    "data = mat['CYratioCyt'][25, 5:]\n",
    "fig = plt.figure()\n",
    "plt.plot(data)\n",
    "plt.xlabel('time (min.)')\n",
    "plt.ylabel('normalized fluorescence (measure of expression)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relational Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///Chinook.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n"
     ]
    }
   ],
   "source": [
    "table_names = engine.table_names()\n",
    "print(table_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workflow of SQL querying\n",
    "● Import packages and functions\n",
    "● Create the database engine\n",
    "● Connect to the engine\n",
    "● Query the database\n",
    "● Save query results to a DataFrame\n",
    "● Close the connection\n",
    "\n",
    "In [1]: from sqlalchemy import create_engine\n",
    "In [2]: import pandas as pd\n",
    "In [3]: engine = create_engine('sqlite:///Northwind.sqlite')\n",
    "In [4]: con = engine.connect()\n",
    "In [5]: rs = con.execute(\"SELECT * FROM Orders\")\n",
    "In [6]: df = pd.DataFrame(rs.fetchall())\n",
    "In [7]: df.columns = rs.keys()\n",
    "In [8]: con.close()\n",
    "    \n",
    "# Using the Context Manager\n",
    "In [1]: from sqlalchemy import create_engine\n",
    "In [2]: import pandas as pd\n",
    "In [3]: engine = create_engine('sqlite:///Northwind.sqlite')\n",
    "In [4]: with engine.connect() as con:\n",
    "   ...: rs = con.execute(\"SELECT OrderID, OrderDate, ShipName FROM Orders\")\n",
    "   ...: df = pd.DataFrame(rs.fetchmany(size=5))\n",
    "   ...: df.columns = rs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customizing the Hello World of SQL Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as con:\n",
    "    rs = con.execute(\"SELECT LastName, Title FROM Employee\")\n",
    "    df = pd.DataFrame(rs.fetchmany(size=3))\n",
    "    df.columns = rs.keys()\n",
    "\n",
    "print(len(df))\n",
    "print(df.head())\n",
    "\n",
    "#\n",
    "3\n",
    "  LastName                Title\n",
    "0    Adams      General Manager\n",
    "1  Edwards        Sales Manager\n",
    "2  Peacock  Sales Support Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering your database records using SQL's WHERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///Chinook.sqlite')\n",
    "\n",
    "with engine.connect() as con:\n",
    "    rs = con.execute(\"SELECT * FROM Employee WHERE EmployeeId >= 6\")\n",
    "    df = pd.DataFrame(rs.fetchall())\n",
    "    df.columns = rs.keys()\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordering your SQL records with ORDER BY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///Chinook.sqlite')\n",
    "\n",
    "with engine.connect() as con:\n",
    "    rs = con.execute(\"SELECT * FROM Employee ORDER BY BirthDate\")\n",
    "    df = pd.DataFrame(rs.fetchall())\n",
    "\n",
    "df.columns = rs.keys()\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying relational databases directly with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In [5]: df = pd.read_sql_query(\"SELECT * FROM Orders\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "# Create engine: engine\n",
    "engine = create_engine('sqlite:///Chinook.sqlite')\n",
    "\n",
    "# Execute query and store records in DataFrame: df\n",
    "df = pd.read_sql_query(\"SELECT * FROM Album\", engine)\n",
    "\n",
    "# Print head of DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Open engine in context manager\n",
    "# Perform query and save results to DataFrame: df1\n",
    "with engine.connect() as con:\n",
    "    rs = con.execute(\"SELECT * FROM Album\")\n",
    "    df1 = pd.DataFrame(rs.fetchall())\n",
    "    df1.columns = rs.keys()\n",
    "\n",
    "# Confirm that both methods yield the same result: does df = df1 ?\n",
    "print(df.equals(df1))\n",
    "\n",
    "   AlbumId                                  Title  ArtistId\n",
    "0        1  For Those About To Rock We Salute You         1\n",
    "1        2                      Balls to the Wall         2\n",
    "2        3                      Restless and Wild         2\n",
    "3        4                      Let There Be Rock         1\n",
    "4        5                               Big Ones         3\n",
    "True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas for more complex querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(\"SELECT * FROM Employee WHERE EmployeeId >= 6 ORDER BY BirthDate\", engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced querying: exploiting table relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In [1]: from sqlalchemy import create_engine\n",
    "In [2]: import pandas as pd\n",
    "In [3]: engine = create_engine('sqlite:///Northwind.sqlite')\n",
    "In [4]: df = pd.read_sql_query(\"SELECT OrderID, CompanyName FROM Orders INNER JOIN Customers on \n",
    "                               Orders.CustomerID = Customers.CustomerID\", engine)\n",
    "In [5]: print(df.head())\n",
    "OrderID CompanyName\n",
    "0 10248 Vins et alcools Chevalier\n",
    "1 10251 Victuailles en stock\n",
    "2 10254 Chop-suey Chinese\n",
    "3 10256 Wellington Importadora\n",
    "4 10258 Ernst Handel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open engine in context manager\n",
    "# Perform query and save results to DataFrame: df\n",
    "with engine.connect() as con:\n",
    "    rs = con.execute(\"SELECT Title, Name FROM Album INNER JOIN Artist on Album.ArtistId = Artist.ArtistId\")\n",
    "    df = pd.DataFrame(rs.fetchall())\n",
    "    df.columns = rs.keys()\n",
    "\n",
    "# Print head of DataFrame df\n",
    "print(df.head())\n",
    "\n",
    "                                   Title       Name\n",
    "0  For Those About To Rock We Salute You      AC/DC\n",
    "1                      Balls to the Wall     Accept\n",
    "2                      Restless and Wild     Accept\n",
    "3                      Let There Be Rock      AC/DC\n",
    "4                               Big Ones  Aerosmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(\"SELECT * FROM PlaylistTrack INNER JOIN Track on \n",
    "     PlaylistTrack.TrackId = Track.TrackId WHERE Milliseconds < 250000\", engine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
